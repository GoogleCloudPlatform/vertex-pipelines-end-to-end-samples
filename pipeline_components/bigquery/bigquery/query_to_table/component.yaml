name: Bq query to table
description: Run query & create a new BigQuery table
inputs:
- {name: query, type: String}
- {name: bq_client_project_id, type: String}
- {name: destination_project_id, type: String}
- {name: dataset_id, type: String, optional: true}
- {name: table_id, type: String, optional: true}
- {name: dataset_location, type: String, default: EU, optional: true}
- {name: query_job_config, type: JsonObject, optional: true}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.30.0' 'kfp==1.8.9' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def bq_query_to_table(
          query: str,
          bq_client_project_id: str,
          destination_project_id: str,
          dataset_id: str = None,
          table_id: str = None,
          dataset_location: str = "EU",
          query_job_config: dict = None,
      ) -> None:
          """
          Run query & create a new BigQuery table
          Args:
              query (str): SQL query to execute, results are saved in a BigQuery table
              bq_client_project_id (str): project id that will be used by the bq client
              destination_project_id (str): project id where BQ table will be created
              dataset_id (str): dataset id where BQ table will be created
              table_id (str): table name (without project id and dataset id)
              dataset_location (str): bq dataset location
              query_job_config (dict): dict containing optional parameters
              required by the bq query operation. No need to specify destination param
              See available parameters here
              https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.QueryJobConfig.html
          Returns:
              None
          """
          from google.cloud.exceptions import GoogleCloudError
          from google.cloud import bigquery
          import logging

          logging.getLogger().setLevel(logging.INFO)

          if (dataset_id is not None) and (table_id is not None):
              dest_table_ref = f"{destination_project_id}.{dataset_id}.{table_id}"
          else:
              dest_table_ref = None
          if query_job_config is None:
              query_job_config = {}
          job_config = bigquery.QueryJobConfig(destination=dest_table_ref, **query_job_config)

          bq_client = bigquery.client.Client(
              project=bq_client_project_id, location=dataset_location
          )
          query_job = bq_client.query(query, job_config=job_config)

          try:
              result = query_job.result()
              logging.info(f"BQ table {dest_table_ref} created")
          except GoogleCloudError as e:
              logging.error(e)
              logging.error(query_job.error_result)
              logging.error(query_job.errors)
              raise e

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - bq_query_to_table
